{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"display: flex; align-items: left;\">\n",
        "    <a href=\"https://sites.google.com/corp/google.com/genai-solutions/home?authuser=0\">\n",
        "        <img src=\"https://storage.googleapis.com/miscfilespublic/Linkedin%20Banner%20%E2%80%93%202.png\" style=\"margin-right\">\n",
        "    </a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "copyright"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyGcAepAPJ5"
      },
      "source": [
        "\n",
        "# **Open Data QnA: Set up BigQuery Source**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook shows how to copy a BigQuery public dataset to your GCP project \n",
        "\n",
        "\n",
        "This is accomplished through the three following steps:  \n",
        "> i. Create a BigQuery dataset in your GCP project\n",
        "\n",
        "> ii. Create a table in the above dataset\n",
        "\n",
        "> iii. Copy data from the public dataset to the dataset on your project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöß **0. Pre-requisites**\n",
        "\n",
        "Make sure that you have completed the intial setup process using [1_SetUpVectorStore.ipynb](1_SetUpVectorStore.ipynb). If the 1_SetUpVectorStore notebook has been run successfully, the following are set up:\n",
        "* GCP project and all the required IAM permissions\n",
        "\n",
        "* **Environment to run the solution**\n",
        "\n",
        "* Data source and Vector store for the solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó **1. Connect Your Google Cloud Project**\n",
        "Time to connect your Google Cloud Project to this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
        "PROJECT_ID = input(\"Enter the project id (same as your SetUpVectorStore) to copy source data in bigquery for this solution\")\n",
        "\n",
        "# Quick input validation\n",
        "assert PROJECT_ID, \"‚ö†Ô∏è Please provide your Google Cloud Project ID\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "print(f'Project has been set to {PROJECT_ID}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygMe6rPWxHS"
      },
      "source": [
        "## üîê **2. Authenticate to Google Cloud**\n",
        "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
        "\n",
        "You can do this within Google Colab or using the Application Default Credentials in the Google Cloud CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PTXN1_DSXj2b"
      },
      "outputs": [],
      "source": [
        "# Authentication step\n",
        "\n",
        "\"\"\"Colab Auth\"\"\" \n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "\n",
        "\"\"\"Jupiter Notebook Auth\"\"\"\n",
        "import google.auth\n",
        "import os\n",
        "\n",
        "credentials, project_id = google.auth.default()\n",
        "\n",
        "os.environ['GOOGLE_CLOUD_QUOTA_PROJECT']=PROJECT_ID\n",
        "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚òÅÔ∏è **Copy a Public Dataset to your GCP Project**\n",
        "\n",
        "Copy a table from the public dataset to ask questions against. A sample table is chosen below, feel free to choose a different one. \n",
        "\n",
        "Note: BigQuery does not allow tables to be copied across regions in certain cases. Therefore, BQ_DST_REGION is set to be BQ_SRC_REGION. Change this parameter to check if copy to your region of interest is allowed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Details of source Dataset\n",
        "BQ_SRC_PROJECT = \"bigquery-public-data\"\n",
        "BQ_SRC_DATASET = \"fda_food\"\n",
        "BQ_SRC_TABLE = \"food_enforcement\"\n",
        "BQ_SRC_REGION= \"us\"\n",
        "\n",
        "# Details of destination Dataset\n",
        "BQ_DST_PROJECT = PROJECT_ID\n",
        "BQ_DST_DATASET = \"fda_food\"\n",
        "BQ_DST_TABLE = \"food_enforcement\"\n",
        "BQ_DST_REGION = BQ_SRC_REGION # Change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createBQDataset(bq_project_id, dataset_name,dataset_region):\n",
        "    from google.cloud import bigquery\n",
        "    import google.api_core \n",
        "\n",
        "    client=bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "    dataset_ref = f\"{bq_project_id}.{dataset_name}\"\n",
        "\n",
        "    try:\n",
        "        client.get_dataset(dataset_ref)\n",
        "        print(\"Destination Dataset exists\")\n",
        "    except google.api_core.exceptions.NotFound:\n",
        "        print(\"Cannot find the dataset hence creating.......\")\n",
        "        dataset=bigquery.Dataset(dataset_ref)\n",
        "        dataset.location=dataset_region\n",
        "        client.create_dataset(dataset)\n",
        "        \n",
        "    return dataset_ref\n",
        "\n",
        "def createBQTable(bq_project_id,dataset_name, table_name):\n",
        "        from google.cloud import bigquery\n",
        "        import google.api_core \n",
        "\n",
        "        client=bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "        table_ref = client.dataset(dataset_name, project=bq_project_id).table(table_name)\n",
        "\n",
        "        try:\n",
        "            client.get_table(table_ref)\n",
        "            print(\"Destination Table exists\")\n",
        "            \n",
        "        except google.api_core.exceptions.NotFound:\n",
        "            print(\"Cannot find the table hence creating.......\")\n",
        "            table = bigquery.Table(table_ref)\n",
        "            client.create_table(table)\n",
        "\n",
        "        return table_ref\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cannot find the dataset hence creating.......\n",
            "Cannot find the table hence creating.......\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CopyJob<project=ten-p-o, location=US, id=959ae62a-3f33-4bb8-9b5c-9abf8dca398d>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create destination table and copy table data\n",
        "from google.cloud import bigquery\n",
        "\n",
        "client=bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "dst_dataset_ref=createBQDataset(BQ_DST_PROJECT,BQ_DST_DATASET,BQ_DST_REGION)\n",
        "\n",
        "dst_table_ref=createBQTable(BQ_DST_PROJECT,BQ_DST_DATASET,BQ_DST_TABLE)\n",
        "\n",
        "src_table_ref = client.dataset(BQ_SRC_DATASET, project=BQ_SRC_PROJECT).table(BQ_SRC_TABLE)\n",
        "\n",
        "job_config = bigquery.CopyJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "\n",
        "copy_job = client.copy_table(src_table_ref, dst_table_ref, job_config=job_config)\n",
        "\n",
        "\n",
        "\n",
        "# Wait for the job to complete and check for errors\n",
        "copy_job.result()  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### If all the above steps are executed suucessfully, the Bigquery Public dataset should be copied to your GCP project"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
